{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Лабораторная работа 3\n",
    "Исследование алгоритмов классификации"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Классы\n",
    "\n",
    "В статистике и анализе данных классом называют группу объектов или явлений, обладающих общими свойствами. Понятие класса играет важную роль в технологиях обнаружения и представление знаний. Например, среди заемщиков банка можно выделить классы добросовестных (которые не допускают просрочки) и недобросовестных (допускают). Также клиентов можно разбить на классы по уровню их активности (активный, пассивный) и т.д.\n",
    "\n",
    "В отличие от кластеров, которые формируются в процессе кластеризации, классы должны быть определены заранее. Поэтому обучение классификаторов — это задача обучения с учителем.\n",
    "\n",
    "Классы бывают:\n",
    "- непересекающиеся -  одно наблюдение может одновременно принадлежать только одному классу;\n",
    "- пересекающиеся - одно и то же наблюдение может принадлежать нескольким классам одновременно;\n",
    "- нечеткими - наблюдение принадлежит к классу с некоторой степенью принадлежности (обычно степень принадлежности задается в интервале от 0 до 1).\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Классификация\n",
    "\n",
    "Одной из важнейших задач анализа данных является классификация — отнесение объектов предметной области к заранее определённым группам, называемым классами. При этом каждому классу должны принадлежать объекты, близкие по своим свойствам. Обобщая свойства известных объектов класса на новые, отнесённые к нему объекты, можно получать знания о них.\n",
    "\n",
    "Задача классификации решается с помощью аналитических моделей, называемых классификаторами. Классифицировать объект означает предъявить набор его признаков (обычно представленных в виде вектора) на вход модели-классификатора, которая должна присвоить ему метку или номер класса.\n",
    "\n",
    "Необходимость использования в анализе данных большого числа разнообразных методов классификации, обусловлена тем, что решаемые с её помощью задачи могут иметь свои особенности, связанные, например, с представлением исходных данных, их количеством и качеством, что требует выбора адекватного классификатора. Поэтому выбор классификатора, соответствующего особенностям решаемой задачи анализа, является важным фактором получения правильного решения.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Алгоритм kNN\n",
    "В случае использования метода для классификации объект присваивается тому классу, который является наиболее распространённым среди k соседей данного элемента, классы которых уже известны.\n",
    "\n",
    "Поскольку признаки, на основе которых производится классификация могут иметь различную физическую природу и, соответственно, диапазоны значений, для улучшения результатов классификации будет полезно выполнить нормализацию обучающих данных."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Для репрезентативности результатов выберем датасет отличающийся от 1,2 лабораторных работ.\n",
    "Описание выбранного датасета представлено [тут](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database?resource=download).\n",
    "\n",
    "За основу выполнения задания был выбран https://www.kaggle.com/code/shrutimechlearn/step-by-step-diabetes-classification-knn-detailed\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### OSEMN Pipeline\n",
    "Перед иследованием алгоритмов классификации необходимо пройти по приведенному пайплайну.\n",
    "\n",
    "O - Obtaining our data\n",
    "S - Scrubbing / Cleaning our data\n",
    "E - Exploring / Visualizing our data will allow us to find patterns and trends\n",
    "M - Modeling our data will give us our predictive power as a wizard\n",
    "N - INterpreting our data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "diabetes_data = pd.read_csv('diabetes.csv')\n",
    "diabetes_data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "diabetes_data.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "diabetes_data.dtypes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## gives information about the data types,columns, null value counts, memory usage etc\n",
    "## https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html\n",
    "diabetes_data.info(verbose=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "diabetes_data_copy = diabetes_data.copy(deep = True)\n",
    "diabetes_data_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = diabetes_data_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0,np.NaN)\n",
    "\n",
    "## showing the count of Nans\n",
    "print(diabetes_data_copy.isnull().sum())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p = diabetes_data.hist(figsize = (20,20))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# На основе построенных выше гистограм заменяем NaN медианой или средним значением в зависимости от распределения\n",
    "diabetes_data_copy['Glucose'].fillna(diabetes_data_copy['Glucose'].mean(), inplace = True)\n",
    "diabetes_data_copy['BloodPressure'].fillna(diabetes_data_copy['BloodPressure'].mean(), inplace = True)\n",
    "diabetes_data_copy['SkinThickness'].fillna(diabetes_data_copy['SkinThickness'].median(), inplace = True)\n",
    "diabetes_data_copy['Insulin'].fillna(diabetes_data_copy['Insulin'].median(), inplace = True)\n",
    "diabetes_data_copy['BMI'].fillna(diabetes_data_copy['BMI'].median(), inplace = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "diabetes_data_copy.hist(figsize = (20,20))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.pairplot(diabetes_data_copy, hue = 'Outcome')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.heatmap(diabetes_data_copy.corr(), annot=True,cmap ='RdYlGn')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X =  pd.DataFrame(sc_X.fit_transform(diabetes_data_copy.drop([\"Outcome\"],axis = 1),),\n",
    "                  columns=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
    "                           'BMI', 'DiabetesPedigreeFunction', 'Age'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#X = diabetes_data.drop(\"Outcome\",axis = 1)\n",
    "y = diabetes_data_copy.Outcome"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train Test Split : To have unknown datapoints to test the data rather than testing with the same points with which the model was trained. This helps capture the model performance much better.\n",
    "[Источник](https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#importing train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=1/3,random_state=42, stratify=y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "test_scores = []\n",
    "train_scores = []\n",
    "\n",
    "for i in range(1,15):\n",
    "\n",
    "    knn = KNeighborsClassifier(i)\n",
    "    knn.fit(X_train,y_train)\n",
    "\n",
    "    train_scores.append(knn.score(X_train,y_train))\n",
    "    test_scores.append(knn.score(X_test,y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## score that comes from testing on the same datapoints that were used for training\n",
    "max_train_score = max(train_scores)\n",
    "train_scores_ind = [i for i, v in enumerate(train_scores) if v == max_train_score]\n",
    "print('Max train score {} % and k = {}'.format(max_train_score*100,list(map(lambda x: x+1, train_scores_ind))))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## score that comes from testing on the datapoints that were split in the beginning to be used for testing solely\n",
    "max_test_score = max(test_scores)\n",
    "test_scores_ind = [i for i, v in enumerate(test_scores) if v == max_test_score]\n",
    "print('Max test score {} % and k = {}'.format(max_test_score*100,list(map(lambda x: x+1, test_scores_ind))))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Визуализируем результаты"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "p = sns.lineplot(x=range(1,15),y=train_scores,marker='*',label='Train Score')\n",
    "p = sns.lineplot(x=range(1,15),y=test_scores,marker='o',label='Test Score')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Определили по графику выше k = 11"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(11)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "knn.score(X_test,y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Сравниv полученные результаты с помощью различных метрик оценки качества\n",
    "\n",
    "#### ROC - AUC\n",
    "[Источник](https://pythonru.com/baza-znanij/sklearn-roc-auc)\n",
    "\n",
    "Полное название ROC — Receiver Operating Characteristic (рабочая характеристика приёмника). Впервые она была создана для использования радиолокационного обнаружения сигналов во время Второй мировой войны. США использовали ROC для повышения точности обнаружения японских самолетов с помощью радара. Поэтому ее называют рабочей характеристикой приемника."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "y_pred_proba = knn.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.plot(fpr,tpr, label='Knn')\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('Knn(n_neighbors=11) ROC curve')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test,y_pred_proba)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Confusion Matrix\n",
    "[Источник](https://medium.com/@djocz/confusion-matrix-aint-that-confusing-d29e18403327)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "confusion_matrix(y_test,y_pred)\n",
    "pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Precision\n",
    "TP – True Positives\n",
    "FP – False Positives\n",
    "Precision – Accuracy of positive predictions.\n",
    "Precision = TP/(TP + FP)\n",
    "\n",
    "Вычисляя руками по формуле получаем такое же значение, что и методом класса \"из коробки\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision_score(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Recall"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recall_score(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### F-measure"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Дерево решений\n",
    "[Источник](https://habr.com/ru/companies/ods/articles/322534/)\n",
    " Деревья решений используются в повседневной жизни в самых разных областях человеческой деятельности, порой и очень далеких от машинного обучения. Деревом решений можно назвать наглядную инструкцию, что делать в какой ситуации."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "\n",
    "# Определим оптимальные параметры для дерева решений\n",
    "tree_params = {\"max_depth\": range(1, 11), \"max_features\": range(4, 19)}\n",
    "tree_grid = GridSearchCV(tree, tree_params, cv=5, n_jobs=-1, verbose=True)\n",
    "tree_grid.fit(X_train,y_train)\n",
    "tree_grid.best_params_, tree_grid.best_score_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_test, tree_grid.predict(X_test))}')\n",
    "print(f'Precision: {precision_score(y_test, tree_grid.predict(X_test))}')\n",
    "print(f'Recall: {recall_score(y_test, tree_grid.predict(X_test))}')\n",
    "print(f'F-measure: {f1_score(y_test, tree_grid.predict(X_test))}')\n",
    "print(f'ROC AUC: {roc_auc_score(y_test, tree_grid.predict(X_test))}')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
